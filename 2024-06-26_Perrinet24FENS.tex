% !TEX encoding = UTF-8 Unicode
% !TEX TS-program = lualatexmk
% !TeX spellcheck = en-US
% !BIB TS-program = bibtex
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8
%
\newcommand{\FirstLP}{Laurent Udo}
\newcommand{\LastLP}{Perrinet}
\newcommand{\AuthorLP}{\FirstLP\ \LastLP}
\newcommand{\EmailLP}{laurent.perrinet@univ-amu.fr}
\newcommand{\orcidLP}{0000-0002-9536-010X}
\newcommand{\Department}{Institut de Neurosciences de la Timone}% (UMR 7289)}%
\newcommand{\Affiliation}{Aix Marseille Univ, CNRS}%
\newcommand{\Street}{27 boulevard Jean Moulin}%
\newcommand{\PostCode}{13005}%
\newcommand{\City}{Marseille}%
\newcommand{\Country}{France}%
\newcommand{\WebsiteLP}{https://laurentperrinet.github.io}%
\newcommand{\Keywords}{time code, event-based computations, spiking neural networks, motion detection, efficient coding, logistic regression
}
\newcommand{\Funding}{
This research was funded by ANR project AgileNeuRobot ANR-20-CE23-0021 (\href{https://laurentperrinet.github.io/grant/anr-anr}{https://laurentperrinet.github.io/grant/anr-anr}) and from A*Midex grant ``Polychronies'' number AMX-21-RID-025 (\href{https://laurentperrinet.github.io/grant/polychronies}{https://laurentperrinet.github.io/grant/polychronies}). 
}
\newcommand{\Acknowledgments}{
The authors thank Salvatore Giancani, Hugo Ladret, Camille Besnainou, Jean-Nicolas Jérémie, Miles Keating, and Adrien Fois for useful discussions during the elaboration of this work. 
\Funding %
%For the purpose of open access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission. This research was funded, in whole or in part, by [Organisation name, Grant #]. 
A CC-BY public copyright license has been applied by the authors to the present document and will be applied to all subsequent versions up to the Author Accepted Manuscript arising from this submission, in accordance with the grant’s open access conditions. 
}
\newcommand{\DataAvailability}{
This work is made reproducible. The code reproducing the manuscript and all figures is available on~\url{https://github.com/SpikeAI/2023_GrimaldiPerrinet_HeterogeneousDelaySNN}. It also contains supplementary figures and results. Find also the associated zotero group used to gather relevant literature on the subject at~\url{https://www.zotero.org/groups/4776796/fastmotiondetection}.
}
%
%% Gemini theme
% https://github.com/anishathalye/gemini

\documentclass[final]{beamer}

% ====================
% Packages
% ====================

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[size=custom,width=120,height=72,scale=1.0]{beamerposter}
\usetheme{gemini}
\usecolortheme{gemini}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tikz} 
\usepackage{pgfplots}
\pgfplotsset{compat=1.14}
\usepackage{anyfontsize} 
% \usepackage{natbib}
\usepackage{siunitx}%The siunitx package provides a  set  of  tools  for  authors  to  typeset  quantities  in  aconsistent  way.

\newcommand{\ms}{\si{\milli\second}}%


  \usepackage[
%  style=chem-acs,
%style=authoryear,
%  style=numeric-comp,
  style=numeric,						% numeric style for reference list
%  style=apa,
%  citestyle=numeric-comp,
  %style=alphabetic-verb,
%  giveninits=false,
%  maxbibnames=1,
  %firstinits=true,
  %maxcitenames=1,
  %maxnames=3,
  %minnames=1,
  %maxbibnames=99,
 % %maxbibnames=99,
 % dateabbrev=true,
 % giveninits=true,
  %uniquename=init,
 % url=false,
 url=true,
 % doi=false,
 % isbn=false,
 % eprint=false,
 % texencoding=utf8,
 % bibencoding=utf8,
 % autocite=superscript,
 % backend=biber,
 backend=bibtex,
  %sorting=none,
  sorting=none,
  sortcites=false,
  %articletitle=false
  ]{biblatex}%

% \usepackage{natbib}

\addbibresource{2024-06-26_Perrinet24FENS.bib}

% ====================
% Lengths
% ====================

% If you have N columns, choose \sepwidth and \colwidth such that
% (N+1)*\sepwidth + N*\colwidth = \paperwidth
\newlength{\sepwidth}
\newlength{\colwidth}
\setlength{\sepwidth}{0.025\paperwidth}
\setlength{\colwidth}{0.3\paperwidth}

\newcommand{\separatorcolumn}{\begin{column}{\sepwidth}\end{column}}

% ====================
% Title
% ====================

\title{Accurate Detection of Spiking Motifs in Neurobiological Data by Learning Heterogeneous Delays
% of a Spiking Neural Network
}

\author{\FirstLP\  \LastLP}

\institute[shortinst]{\Department, \Affiliation,  \Street, \City\ \Country}

% ====================
% Footer (optional)
% ====================

\footercontent{
  \href{https://laurentperrinet.github.io/publication/perrinet-24-fens/}{https://laurentperrinet.github.io/publication/perrinet-24-fens/} \hfill
  FENS Forum Conference 2024, Vienna \includegraphics[height=2.5cm]{figures/qr_code.png}  \hfill
  \href{mailto:\EmailLP}{\EmailLP}   }
% (can be left out to remove footer)

% ====================
% Logo (optional)
% ====================

% use this to include logos on the left and/or right side of the header:
% \logoright{\includegraphics[height=7cm]{logo1.pdf}}
% \logoleft{\includegraphics[height=7cm]{logo2.pdf}}

% ====================
% Body
% ====================

\begin{document}

\begin{frame}[t]
\begin{columns}[t]
\separatorcolumn

\begin{column}{\colwidth}

  \begin{block}{Precise spiking motifs in neurobiological and neuromorphic data~\parencite{Grimaldi22polychronies}}


\begin{figure}[H]
%\centering
\includegraphics[width=\textwidth]{figures/replicating_MainenSejnowski1995.pdf} 
\caption{
 \textbf{Reproducibility of the spiking response of a neuron.} 
The timing of the spikes produced following the repetition of a step stimulus is less reproducible than that to a noisy stimulus. The stimulus current value over time for a step stimulus (top left) and for a noisy one (top right). Trial repetitions of a leaky integrate-and-fire neuron stimulated by the stimulus on the upper row (middle row). Membrane potential is represented by dark blue color when light yellow colors when depolarized) and quantified by the average firing rate across trials (lower row). While this seems paradoxical at first sight, it highlights the consequence of using the same frozen noise at each repetition and highlights the highly reproducible pattern of spikes when it is driven by a highly dynamic input. See this~\href{https://github.com/laurentperrinet/2022_UE-neurosciences-computationnelles/blob/master/C_MainenSejnowski1995_Perrinet.ipynb}{online notebook}  for a replication of the results from~\parencite{mainen_reliability_1995} using a simple LIF model.}\label{fig:mainen}
\end{figure}
    

%    \begin{figure}
%      \centering
%      \begin{tikzpicture}[scale=6]
%        \draw[step=0.25cm,color=gray] (-1,-1) grid (1,1);
%        \draw (1,0) -- (0.2,0.2) -- (0,1) -- (-0.2,0.2) -- (-1,0)
%          -- (-0.2,-0.2) -- (0,-1) -- (0.2,-0.2) -- cycle;
%      \end{tikzpicture}
%      \caption{A figure caption.}
%    \end{figure}

    \begin{figure}[H]%[t!]
      %  \centering 
        \includegraphics[width=0.900\linewidth]{figures/izhikevich.pdf}%png}% https://www.overleaf.com/5625872443qpcwrkssgbsf
          \caption{\textbf{Core mechanism of polychrony detection~\textcite{izhikevich_polychronization_2006}.} {(\textit{Left})}~In this example, three presynaptic neurons denoted \textit{b}, \textit{c} and, \textit{d} are fully connected to two post-synaptic neurons \textit{a} and \textit{e}, with different delays of respectively $1$, $5$, and $9~\ms$ for \textit{a} and  $8$, $5$, and $1~\ms$ for \textit{e}. {(\textit{Middle})}~If three synchronous pulses are emitted from presynaptic neurons, this will generate post-synaptic potentials that will reach \textit{a} and \textit{e} asynchronously because of the heterogeneous delays, and they may not be sufficient to reach the membrane threshold in either of the post-synaptic neurons; therefore, no spike will be emitted, as this is not sufficient to reach the membrane threshold of the post synaptic neuron, so no output spike is emitted.
          %at these different delays, and these may not be sufficient to generate a spike in either neuron.
          {(\textit{Right})}~If the pulses are emitted from presynaptic neurons such that, taking into account the delays, they reach the post-synaptic neuron \textit{a} at the same time (here, at $t=10~\ms$),  the post-synaptic potentials evoked by the three pre-synaptic neurons sum up, causing the voltage threshold to be crossed and thus to the emission of an output spike (red color), while none is emitted from post-synaptic neuron \textit{e}.
           }
        \label{fig:izhikevich}
      \end{figure}
      %
%
%    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi ultricies
%    eget libero ac ullamcorper. Integer et euismod ante. Aenean vestibulum
%    lobortis augue, ut lobortis turpis rhoncus sed. Proin feugiat nibh a
%    lacinia dignissim. Proin scelerisque, risus eget tempor fermentum, ex
%    turpis condimentum urna, quis malesuada sapien arcu eu purus.

  \end{block}

%  \begin{block}{A block containing a list}
%
%    Nam vulputate nunc felis, non condimentum lacus porta ultrices. Nullam sed
%    sagittis metus. Etiam consectetur gravida urna quis suscipit.
%
%    \begin{itemize}
%      \item \textbf{Mauris tempor} risus nulla, sed ornare
%      \item \textbf{Libero tincidunt} a duis congue vitae
%      \item \textbf{Dui ac pretium} morbi justo neque, ullamcorper
%    \end{itemize}
%
%    Eget augue porta, bibendum venenatis tortor.
%
%  \end{block}
%
%  \begin{alertblock}{A highlighted block}
%
%    This block catches your eye, so \textbf{important stuff} should probably go
%    here.
%
%    Curabitur eu libero vehicula, cursus est fringilla, luctus est. Morbi
%    consectetur mauris quam, at finibus elit auctor ac. Aliquam erat volutpat.
%    Aenean at nisl ut ex ullamcorper eleifend et eu augue. Aenean quis velit
%    tristique odio convallis ultrices a ac odio.
%
%    \begin{itemize}
%      \item \textbf{Fusce dapibus tellus} vel tellus semper finibus. In
%        consequat, nibh sed mattis luctus, augue diam fermentum lectus.
%      \item \textbf{In euismod erat metus} non ex. Vestibulum luctus augue in
%        mi condimentum, at sollicitudin lorem viverra.
%      \item \textbf{Suspendisse vulputate} mauris vel placerat consectetur.
%        Mauris semper, purus ac hendrerit molestie, elit mi dignissim odio, in
%        suscipit felis sapien vel ex.
%    \end{itemize}
%
%    Aenean tincidunt risus eros, at gravida lorem sagittis vel. Vestibulum ante
%    ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae.
%
%  \end{alertblock}
  \begin{alertblock}{Acknowledgments}
  \Funding
  \end{alertblock}
\end{column}

\separatorcolumn

\begin{column}{\colwidth}

   \begin{block}{Heterogeneous Delays Spiking Neural Network (HD-SNN)~\parencite{Grimaldi23BC}}

  %   Vivamus congue volutpat elit non semper. Praesent molestie nec erat ac
  %   interdum. In quis suscipit erat. \textbf{Phasellus mauris felis, molestie
  %   ac pharetra quis}, tempus nec ante. Donec finibus ante vel purus mollis
  %   fermentum. Sed felis mi, pharetra eget nibh a, feugiat eleifend dolor. Nam
  %   mollis condimentum purus quis sodales. Nullam eu felis eu nulla eleifend
  %   bibendum nec eu lorem. Vivamus felis velit, volutpat ut facilisis ac,
  %   commodo in metus.

  %   \begin{enumerate}
  %     \item \textbf{Morbi mauris purus}, egestas at vehicula et, convallis
  %       accumsan orci. Orci varius natoque penatibus et magnis dis parturient
  %       montes, nascetur ridiculus mus.
  %     \item \textbf{Cras vehicula blandit urna ut maximus}. Aliquam blandit nec
  %       massa ac sollicitudin. Curabitur cursus, metus nec imperdiet bibendum,
  %       velit lectus faucibus dolor, quis gravida metus mauris gravida turpis.
  %     \item \textbf{Vestibulum et massa diam}. Phasellus fermentum augue non
  %       nulla accumsan, non rhoncus lectus condimentum.
  %   \end{enumerate}

  % \end{block}

  % \begin{block}{Fusce aliquam magna velit}

  %   Et rutrum ex euismod vel. Pellentesque ultricies, velit in fermentum
  %   vestibulum, lectus nisi pretium nibh, sit amet aliquam lectus augue vel
  %   velit. Suspendisse rhoncus massa porttitor augue feugiat molestie. Sed
  %   molestie ut orci nec malesuada. Sed ultricies feugiat est fringilla
  %   posuere.

\begin{figure}%[h!]%[htbt]
%\begin{wrapfigure}{R}{0.31\textwidth}
	{ \centering
	\includegraphics[width=.9\textwidth]{figures/event_driven_computations.pdf}
	\caption{\small %\footnotesize        
	\textbf{ Event-based cameras.}
	A miniature ATIS sensor. Contrary to a classical frame-based camera for which a full dense image representation is given at discrete, regularly spaced timings, the event-based camera provides with events at the micro-second resolution. These are sparse as they represent luminance increments or decrements (ON and OFF events, respectively).
	}
	\label{fig:silicon_retina}
		}
\end{figure}
%%%-----------------------------------------------------------------
%: fig:motion_task
%%%-----------------------------------------------------------------
\begin{figure}%
    \centering
    \includegraphics[width=0.95\linewidth]{figures/motion_task.pdf}
    \caption{
       \textbf{ Motion Detection Task.} To generate realistic event-based dynamic scenes, we mimic the effect of minute saccadic eye movements on a large natural scene ($1024\times1024$) by extracting an image ($128\times128$) which center is moving dynamically according to a jagged random walk. \textit{(Left)}~We show an instance of this trajectory (with a length of $200~\ms$, green line) superimposed on the luminance contrasts observed at time step $t=15~\ms$. \textit{(Right)}~The dynamics of this image, translated according to the saccadic trajectory, produces a naturalistic movie, which is then transformed into an event-based representation. We show snapshots of the resulting synthetic event stream at different time steps .% (from $t=15~\ms$ to $t=19~\ms$, these frames are marked on the trajectory by a white and black dot, respectively, in the left inset).
         Mimicking the response of ganglion cells in the retina, this representation encodes at each pixel all-or-none increases or decreases in luminance, i.e., ON (red) and OFF (blue) spikes. In the lower left corner of the snapshots, we show the corresponding instantaneous motion vector (red arrow). %Note the change in the direction of motion between the third and fourth frames, and also that contours parallel to the motion produce fewer luminance changes, the so-called aperture problem, and thus relatively fewer spikes.
        }
    \label{fig:motion_task}
\end{figure}
%%%-----------------------------------------------------------------

\begin{columns}[t]
\separatorcolumn

\begin{column}{.48\colwidth}

\begin{figure}
    {\centering
    %\vspace{-3cm}
    \includegraphics[width=.9\linewidth]{figures/motion_kernels.pdf}
    }
    %\vspace{-.5cm}
    \caption{
    	Representation of the weights for $8$ directions for a single speed (among the $12 \times 3$ different kernels of the model) as learned on the dataset of naturalistic scenes. The directions are shown as red arrows in the left insets, where the disks correspond to the set of different possible motions. The spatiotemporal kernels are shown as slices of spatial weights at different delays. Delays vary along the horizontal axis from the far right (delay of one step) to the left (up to a delay of $12$ steps, the remaining synapses being not represented). %Each image corresponds to the weights at a given delay, with excitatory and inhibitory weights in warm and cold colors, respectively. Due to the symmetry between the ON and OFF event streams, we observed that the kernels for the OFF polarities are very similar and are not shown here.	Different kernels are selective for the different motion directions, and we observe a slight orientation preference perpendicular to the respective direction for all kernels.
	}
    \label{fig:kernels}
\end{figure} 
\end{column}
%
\begin{column}{.48\colwidth}
\begin{figure}%[h!]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/quant_accuracy.pdf}
    \caption{
        Accuracy as a function of computational load for the HD-SNN model (blue dots) with error bars indicating the 5\% - 95\% quantiles and a sigmoid fit (blue line). The relative computational load (on a logarithmic axis) is controlled by changing the percentage of nonzero weights relative to the dense convolution kernel. If we shorten the length of the kernel by using only the weights at the shortest delays, the accuracy quickly drops. %However, if we prune the lowest coefficients from the whole kernel, we observe a stable accuracy value, with a drop to half-saturation observed at about $670$ times fewer computations.
        }
    \label{fig:accuracy}
\end{figure}
\end{column}
\end{columns}

  \end{block}

%  \begin{block}{Nam cursus consequat egestas}
%
%    Nulla eget sem quam. Ut aliquam volutpat nisi vestibulum convallis. Nunc a
%    lectus et eros facilisis hendrerit eu non urna. Interdum et malesuada fames
%    ac ante \textit{ipsum primis} in faucibus. Etiam sit amet velit eget sem
%    euismod tristique. Praesent enim erat, porta vel mattis sed, pharetra sed
%    ipsum. Morbi commodo condimentum massa, \textit{tempus venenatis} massa
%    hendrerit quis. Maecenas sed porta est. Praesent mollis interdum lectus,
%    sit amet sollicitudin risus tincidunt non.
%
%    Etiam sit amet tempus lorem, aliquet condimentum velit. Donec et nibh
%    consequat, sagittis ex eget, dictum orci. Etiam quis semper ante. Ut eu
%    mauris purus. Proin nec consectetur ligula. Mauris pretium molestie
%    ullamcorper. Integer nisi neque, aliquet et odio non, sagittis porta justo.
%
%    \begin{itemize}
%      \item \textbf{Sed consequat} id ante vel efficitur. Praesent congue massa
%        sed est scelerisque, elementum mollis augue iaculis.
%        \begin{itemize}
%          \item In sed est finibus, vulputate
%            nunc gravida, pulvinar lorem. In maximus nunc dolor, sed auctor eros
%            porttitor quis.
%          \item Fusce ornare dignissim nisi. Nam sit amet risus vel lacus
%            tempor tincidunt eu a arcu.
%          \item Donec rhoncus vestibulum erat, quis aliquam leo
%            gravida egestas.
%        \end{itemize}
%      \item \textbf{Sed luctus, elit sit amet} dictum maximus, diam dolor
%        faucibus purus, sed lobortis justo erat id turpis.
%      \item \textbf{Pellentesque facilisis dolor in leo} bibendum congue.
%        Maecenas congue finibus justo, vitae eleifend urna facilisis at.
%    \end{itemize}
%
%  \end{block}

\end{column}

\separatorcolumn

\begin{column}{\colwidth}

  \begin{exampleblock}{Detection of Spiking Motifs by Learning a HD-SNN~\parencite{Perrinet23ICANN}}

%
%    A different kind of highlighted block.
%
%    $$
%    \int_{-\infty}^{\infty} e^{-x^2}\,dx = \sqrt{\pi}
%    $$
%
%    Interdum et malesuada fames $\{1, 4, 9, \ldots\}$ ac ante ipsum primis in
%    faucibus. Cras eleifend dolor eu nulla suscipit suscipit. Sed lobortis non
%    felis id vulputate.
%
%    \heading{A heading inside a block}
%
%    Praesent consectetur mi $x^2 + y^2$ metus, nec vestibulum justo viverra
%    nec. Proin eget nulla pretium, egestas magna aliquam, mollis neque. Vivamus
%    dictum $\mathbf{u}^\intercal\mathbf{v}$ sagittis odio, vel porta erat
%    congue sed. Maecenas ut dolor quis arcu auctor porttitor.
%
%    \heading{Another heading inside a block}
%
%    Sed augue erat, scelerisque a purus ultricies, placerat porttitor neque.
%    Donec $P(y \mid x)$ fermentum consectetur $\nabla_x P(y \mid x)$ sapien
%    sagittis egestas. Duis eget leo euismod nunc viverra imperdiet nec id
%    justo.
%---------------------------
\begin{figure}%[t]%[h!]
% \begin{center}
  \includegraphics[width=.40\colwidth]{figures/THC_toy-a_k.pdf}
  \includegraphics[width=.40\colwidth]{figures/THC_toy-b.pdf}
  \\
  \includegraphics[width=.40\colwidth]{figures/THC_toy-c.pdf}
  \includegraphics[width=.40\colwidth]{figures/THC_toy-a.pdf} 
% \end{center}
\caption{\textbf{From generating raster plots to inferring spiking motifs}. \textit{(a)}~As an illustration for the generative model, we draw a multiunit raster plot synthesized from $4$ different spiking motifs and for $10$ presynaptic neurons. \textit{(b)}~We show these motifs, each identified at the top by a different color. The evidence of activation (red) or deactivation (blue) is assigned to each presynaptic neuron and $31$ different possible delays. \textit{(c)}~The activation in time of the different motifs (denoted by stars) is drawn at random and then used to generate a raster plot on the multi-unit address space (see panel a). By inverting this model, an inference model can be defined for their efficient detection, outputting an evidence value (continuous line) from which the identity and timing of SMs can be inferred (vertical bars). \textit{(d)}~The original raster plot can be annotated with each identified spiking motif (as represented by the respective color assigned to SMs).
}
\label{fig:THC}
\end{figure}
%---------------------------
  \end{exampleblock}

%  \begin{block}{Nullam vel erat at velit convallis laoreet}
%
%    Class aptent taciti sociosqu ad litora torquent per conubia nostra, per
%    inceptos himenaeos. Phasellus libero enim, gravida sed erat sit amet,
%    scelerisque congue diam. Fusce dapibus dui ut augue pulvinar iaculis.
%
%    \begin{table}
%      \centering
%      \begin{tabular}{l r r c}
%        \toprule
%        \textbf{First column} & \textbf{Second column} & \textbf{Third column} & \textbf{Fourth} \\
%        \midrule
%        Foo & 13.37 & 384,394 & $\alpha$ \\
%        Bar & 2.17 & 1,392 & $\beta$ \\
%        Baz & 3.14 & 83,742 & $\delta$ \\
%        Qux & 7.59 & 974 & $\gamma$ \\
%        \bottomrule
%      \end{tabular}
%      \caption{A table caption.}
%    \end{table}
%
%    Donec quis posuere ligula. Nunc feugiat elit a mi malesuada consequat. Sed
%    imperdiet augue ac nibh aliquet tristique. Aenean eu tortor vulputate,
%    eleifend lorem in, dictum urna. Proin auctor ante in augue tincidunt
%    tempor. Proin pellentesque vulputate odio, ac gravida nulla posuere
%    efficitur. Aenean at velit vel dolor blandit molestie. Mauris laoreet
%    commodo quam, non luctus nibh ullamcorper in. Class aptent taciti sociosqu
%    ad litora torquent per conubia nostra, per inceptos himenaeos.
%
%    Nulla varius finibus volutpat. Mauris molestie lorem tincidunt, iaculis
%    libero at, gravida ante. Phasellus at felis eu neque suscipit suscipit.
%    Integer ullamcorper, dui nec pretium ornare, urna dolor consequat libero,
%    in feugiat elit lorem euismod lacus. Pellentesque sit amet dolor mollis,
%    auctor urna non, tempus sem.
%
%
%  \end{block}

\nocite{*}
%  \begin{block}{References}
%    
%    \footnotesize{
%%    \bibliographystyle{plain}\bibliography{2024-06-26_Perrinet24FENS}
%     \printbibliography[heading=none]
% }
%  \end{block}
 \begin{block}{References}
    % \nocite{*}
    \footnotesize{
%    \bibliographystyle{plain}\bibliography{2024-06-26_Perrinet24FENS}
     \printbibliography[heading=none]
 }
\end{block}

\end{column}

\separatorcolumn
\end{columns}
\end{frame}

\end{document}
